{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[과제_3]_Keras_Fraud_Detection_Modeling_설정아 CPU.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2Pr7oBdYLdf"
      },
      "source": [
        "# Kaggle 신용카드 사기 검출 (Google Drive Mount)\n",
        "https://www.kaggle.com/mlg-ulb/creditcardfraud\n",
        "## Credit Card Fraud Detection\n",
        "* creditcard.csv (284,807 * 31)\n",
        "* Class : 0 (정상), 1 (사기)\n",
        "* 사기 검출(Fraud Detection), 이상 탐지(Anomaly Detection)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbPgODpVzdHI"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hp2jzMV4Eb0e"
      },
      "source": [
        "# I. Google Drive Mount\n",
        "* 'creditCardFraud.zip' 파일을 구글드라이브에 업로드 후 진행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkooevWlEpae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c39fd60-2de7-4ad9-91ac-077695f1bef1"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBrMKlsgEvV7"
      },
      "source": [
        "* 마운트 결과 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAA_YjrVExu7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dcf66a0-7376-4556-ac97-b96aae3e9f48"
      },
      "source": [
        "!ls -l '/content/drive/My Drive/Colab Notebooks/datasets/creditCardFraud.zip'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw------- 1 root root 69155672 Mar 31 15:04 '/content/drive/My Drive/Colab Notebooks/datasets/creditCardFraud.zip'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DyFdyVxFyHK"
      },
      "source": [
        "# II. Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9zdBsGKnLUo"
      },
      "source": [
        "> ## 1) Unzip 'creditCardFraud.zip'\n",
        "\n",
        "* Colab 파일시스템에 'creditcard.csv' 파일 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkuHaDXcnUtY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71830f2b-15e5-40b5-f803-e122dab53e83"
      },
      "source": [
        "!unzip /content/drive/My\\ Drive/Colab\\ Notebooks/datasets/creditCardFraud.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/My Drive/Colab Notebooks/datasets/creditCardFraud.zip\n",
            "  inflating: creditcard.csv          \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_8T9fKaE1Dh"
      },
      "source": [
        "* creditcard.csv 파일 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcWMC7zwExLX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "565aa288-3cea-473f-a0a6-e9536edd5b97"
      },
      "source": [
        "!ls -l"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 147304\n",
            "-rw-r--r-- 1 root root 150828752 Sep 20  2019 creditcard.csv\n",
            "drwx------ 5 root root      4096 Sep 29 00:55 drive\n",
            "drwxr-xr-x 1 root root      4096 Sep 16 13:40 sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1IbUVmgFJWi"
      },
      "source": [
        "> ## 2) 데이터 읽어오기\n",
        "\n",
        "* pandas DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyKuNQuXEywU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65aa7692-747d-4d38-e45e-698e94f02c60"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "DF = pd.read_csv('creditcard.csv')\n",
        "\n",
        "DF.info()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 284807 entries, 0 to 284806\n",
            "Data columns (total 31 columns):\n",
            " #   Column  Non-Null Count   Dtype  \n",
            "---  ------  --------------   -----  \n",
            " 0   Time    284807 non-null  float64\n",
            " 1   V1      284807 non-null  float64\n",
            " 2   V2      284807 non-null  float64\n",
            " 3   V3      284807 non-null  float64\n",
            " 4   V4      284807 non-null  float64\n",
            " 5   V5      284807 non-null  float64\n",
            " 6   V6      284807 non-null  float64\n",
            " 7   V7      284807 non-null  float64\n",
            " 8   V8      284807 non-null  float64\n",
            " 9   V9      284807 non-null  float64\n",
            " 10  V10     284807 non-null  float64\n",
            " 11  V11     284807 non-null  float64\n",
            " 12  V12     284807 non-null  float64\n",
            " 13  V13     284807 non-null  float64\n",
            " 14  V14     284807 non-null  float64\n",
            " 15  V15     284807 non-null  float64\n",
            " 16  V16     284807 non-null  float64\n",
            " 17  V17     284807 non-null  float64\n",
            " 18  V18     284807 non-null  float64\n",
            " 19  V19     284807 non-null  float64\n",
            " 20  V20     284807 non-null  float64\n",
            " 21  V21     284807 non-null  float64\n",
            " 22  V22     284807 non-null  float64\n",
            " 23  V23     284807 non-null  float64\n",
            " 24  V24     284807 non-null  float64\n",
            " 25  V25     284807 non-null  float64\n",
            " 26  V26     284807 non-null  float64\n",
            " 27  V27     284807 non-null  float64\n",
            " 28  V28     284807 non-null  float64\n",
            " 29  Amount  284807 non-null  float64\n",
            " 30  Class   284807 non-null  int64  \n",
            "dtypes: float64(30), int64(1)\n",
            "memory usage: 67.4 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAK4c1S8GCeR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "outputId": "c34bf495-0912-4032-d271-0b14c50a8598"
      },
      "source": [
        "DF.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>0.090794</td>\n",
              "      <td>-0.551600</td>\n",
              "      <td>-0.617801</td>\n",
              "      <td>-0.991390</td>\n",
              "      <td>-0.311169</td>\n",
              "      <td>1.468177</td>\n",
              "      <td>-0.470401</td>\n",
              "      <td>0.207971</td>\n",
              "      <td>0.025791</td>\n",
              "      <td>0.403993</td>\n",
              "      <td>0.251412</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>-0.166974</td>\n",
              "      <td>1.612727</td>\n",
              "      <td>1.065235</td>\n",
              "      <td>0.489095</td>\n",
              "      <td>-0.143772</td>\n",
              "      <td>0.635558</td>\n",
              "      <td>0.463917</td>\n",
              "      <td>-0.114805</td>\n",
              "      <td>-0.183361</td>\n",
              "      <td>-0.145783</td>\n",
              "      <td>-0.069083</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>0.207643</td>\n",
              "      <td>0.624501</td>\n",
              "      <td>0.066084</td>\n",
              "      <td>0.717293</td>\n",
              "      <td>-0.165946</td>\n",
              "      <td>2.345865</td>\n",
              "      <td>-2.890083</td>\n",
              "      <td>1.109969</td>\n",
              "      <td>-0.121359</td>\n",
              "      <td>-2.261857</td>\n",
              "      <td>0.524980</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>-0.054952</td>\n",
              "      <td>-0.226487</td>\n",
              "      <td>0.178228</td>\n",
              "      <td>0.507757</td>\n",
              "      <td>-0.287924</td>\n",
              "      <td>-0.631418</td>\n",
              "      <td>-1.059647</td>\n",
              "      <td>-0.684093</td>\n",
              "      <td>1.965775</td>\n",
              "      <td>-1.232622</td>\n",
              "      <td>-0.208038</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>0.753074</td>\n",
              "      <td>-0.822843</td>\n",
              "      <td>0.538196</td>\n",
              "      <td>1.345852</td>\n",
              "      <td>-1.119670</td>\n",
              "      <td>0.175121</td>\n",
              "      <td>-0.451449</td>\n",
              "      <td>-0.237033</td>\n",
              "      <td>-0.038195</td>\n",
              "      <td>0.803487</td>\n",
              "      <td>0.408542</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Time        V1        V2        V3  ...       V27       V28  Amount  Class\n",
              "0   0.0 -1.359807 -0.072781  2.536347  ...  0.133558 -0.021053  149.62      0\n",
              "1   0.0  1.191857  0.266151  0.166480  ... -0.008983  0.014724    2.69      0\n",
              "2   1.0 -1.358354 -1.340163  1.773209  ... -0.055353 -0.059752  378.66      0\n",
              "3   1.0 -0.966272 -0.185226  1.792993  ...  0.062723  0.061458  123.50      0\n",
              "4   2.0 -1.158233  0.877737  1.548718  ...  0.219422  0.215153   69.99      0\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIEYGzLnLuxL"
      },
      "source": [
        "* 0 (정상) Class와 1 (사기) Class 개수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4NroBx4JDeP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d71908c-ad85-4f59-bae2-6473dc9b2dba"
      },
      "source": [
        "DF.Class.value_counts()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    284315\n",
              "1       492\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OncXWy-mMF2j"
      },
      "source": [
        "* 0 (정상) Class와 1 (사기) Class 비율"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HWyf0GMJipF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dde44a8-3473-4c71-88e5-96bd6be6efcc"
      },
      "source": [
        "(DF.Class.value_counts() / DF.shape[0]) * 100"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    99.827251\n",
              "1     0.172749\n",
              "Name: Class, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUf0Vq7kG0FQ"
      },
      "source": [
        "> ## 3) Time 열(Column) 삭제"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECv33P4FHE1F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "88d3a2a0-4511-459e-c425-af09c8557cdf"
      },
      "source": [
        "DF.drop('Time', axis = 1, inplace = True)\n",
        "\n",
        "DF.head(1)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>0.090794</td>\n",
              "      <td>-0.5516</td>\n",
              "      <td>-0.617801</td>\n",
              "      <td>-0.99139</td>\n",
              "      <td>-0.311169</td>\n",
              "      <td>1.468177</td>\n",
              "      <td>-0.470401</td>\n",
              "      <td>0.207971</td>\n",
              "      <td>0.025791</td>\n",
              "      <td>0.403993</td>\n",
              "      <td>0.251412</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         V1        V2        V3        V4  ...       V27       V28  Amount  Class\n",
              "0 -1.359807 -0.072781  2.536347  1.378155  ...  0.133558 -0.021053  149.62      0\n",
              "\n",
              "[1 rows x 30 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uF_FNdiaHcFi"
      },
      "source": [
        "> ## 4) train_test_split( )\n",
        "\n",
        "* X (Input), y (Output) 지정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRQX3mslHhC2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70665406-4fba-4f45-808f-f499fc748d02"
      },
      "source": [
        "X = DF.iloc[:,:-1]\n",
        "y = DF.iloc[:, -1]\n",
        "\n",
        "X.shape, y.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((284807, 29), (284807,))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f53LeC-IMx_T"
      },
      "source": [
        "* With 'Stratify'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4e13zFqH0xP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c88227f-4e94-441f-dd30-85f85091a8dc"
      },
      "source": [
        "from sklearn.model_selection import train_test_split \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size = 0.3,\n",
        "                                                    random_state = 2045,\n",
        "                                                    stratify = y)\n",
        "\n",
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((199364, 29), (199364,), (85443, 29), (85443,))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8NA1xnGNTtY"
      },
      "source": [
        "* Train_Data와 Test_Data의 1 (부정) 비율이 균형"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMk7PWicKyDB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8478ce7b-cd6d-4761-a3a4-e3455d4160a1"
      },
      "source": [
        "print('Train_Data :','\\n', (y_train.value_counts() / y_train.shape[0]) * 100)\n",
        "print('Test_Data :','\\n', (y_test.value_counts() / y_test.shape[0]) * 100)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train_Data : \n",
            " 0    99.827451\n",
            "1     0.172549\n",
            "Name: Class, dtype: float64\n",
            "Test_Data : \n",
            " 0    99.826785\n",
            "1     0.173215\n",
            "Name: Class, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvsN9jNLDQO6"
      },
      "source": [
        "# I. Keras Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FV8W8pDnDeZY"
      },
      "source": [
        "## 1) Model Define"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCLfUDgBDpQl",
        "outputId": "73b6c46a-c6cf-43d0-ba47-fe79078cdff0"
      },
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "Model_fd = models.Sequential()\n",
        "Model_fd.add(layers.Dense(10, activation = 'relu', input_shape=(29,)))\n",
        "Model_fd.add(layers.Dense(6, activation = 'relu'))\n",
        "Model_fd.add(layers.Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "Model_fd.summary()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_9 (Dense)              (None, 10)                300       \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 6)                 66        \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1)                 7         \n",
            "=================================================================\n",
            "Total params: 373\n",
            "Trainable params: 373\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "dvQ0SyByFYr0",
        "outputId": "cf320825-3146-48bd-dcff-0e4541fc0926"
      },
      "source": [
        "# 모델 레이어 시각화\n",
        "\n",
        "from tensorflow.keras import utils\n",
        "\n",
        "utils.plot_model(Model_fd,\n",
        "                 show_shapes = True, \n",
        "                 show_dtype = True)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eH802XK_FrTZ"
      },
      "source": [
        "## 2) Model Compile"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2r6qam3FYpX"
      },
      "source": [
        "from tensorflow.keras import metrics\n",
        "\n",
        "Model_fd.compile(loss = 'binary_crossentropy',\n",
        "                 optimizer = 'adam',\n",
        "                 metrics = [metrics.Recall()])"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TcFP6_xHFKM"
      },
      "source": [
        "## 3) Model Fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUBGFbLXFYmN",
        "outputId": "7db363dd-2780-42c3-d1ef-a6a2365ff3c6"
      },
      "source": [
        "history_fd = Model_fd.fit(X_train, y_train,\n",
        "                          epochs = 300,\n",
        "                          batch_size = 1024,\n",
        "                          validation_data = (X_test, y_test))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "195/195 [==============================] - 2s 5ms/step - loss: 0.1091 - recall: 0.2384 - val_loss: 0.0371 - val_recall: 0.5203\n",
            "Epoch 2/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0227 - recall: 0.5669 - val_loss: 0.0104 - val_recall: 0.7432\n",
            "Epoch 3/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0116 - recall: 0.6773 - val_loss: 0.0080 - val_recall: 0.8041\n",
            "Epoch 4/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0066 - recall: 0.7326 - val_loss: 0.0054 - val_recall: 0.8108\n",
            "Epoch 5/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0052 - recall: 0.7151 - val_loss: 0.0040 - val_recall: 0.7973\n",
            "Epoch 6/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0047 - recall: 0.7384 - val_loss: 0.0035 - val_recall: 0.7703\n",
            "Epoch 7/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0045 - recall: 0.7093 - val_loss: 0.0034 - val_recall: 0.7973\n",
            "Epoch 8/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0044 - recall: 0.7238 - val_loss: 0.0033 - val_recall: 0.8041\n",
            "Epoch 9/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0043 - recall: 0.7209 - val_loss: 0.0035 - val_recall: 0.7973\n",
            "Epoch 10/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0040 - recall: 0.7180 - val_loss: 0.0037 - val_recall: 0.8176\n",
            "Epoch 11/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0038 - recall: 0.7326 - val_loss: 0.0032 - val_recall: 0.8108\n",
            "Epoch 12/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0043 - recall: 0.7180 - val_loss: 0.0051 - val_recall: 0.8311\n",
            "Epoch 13/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0047 - recall: 0.7180 - val_loss: 0.0031 - val_recall: 0.8311\n",
            "Epoch 14/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0037 - recall: 0.7297 - val_loss: 0.0031 - val_recall: 0.6959\n",
            "Epoch 15/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0037 - recall: 0.7180 - val_loss: 0.0031 - val_recall: 0.7905\n",
            "Epoch 16/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0035 - recall: 0.7355 - val_loss: 0.0030 - val_recall: 0.8176\n",
            "Epoch 17/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0036 - recall: 0.7355 - val_loss: 0.0031 - val_recall: 0.7297\n",
            "Epoch 18/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0038 - recall: 0.7267 - val_loss: 0.0033 - val_recall: 0.8311\n",
            "Epoch 19/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0036 - recall: 0.7384 - val_loss: 0.0030 - val_recall: 0.8041\n",
            "Epoch 20/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0032 - recall: 0.7413 - val_loss: 0.0031 - val_recall: 0.7905\n",
            "Epoch 21/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0032 - recall: 0.7209 - val_loss: 0.0043 - val_recall: 0.8108\n",
            "Epoch 22/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0036 - recall: 0.7442 - val_loss: 0.0030 - val_recall: 0.8041\n",
            "Epoch 23/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0034 - recall: 0.7326 - val_loss: 0.0040 - val_recall: 0.7297\n",
            "Epoch 24/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0038 - recall: 0.7384 - val_loss: 0.0047 - val_recall: 0.8378\n",
            "Epoch 25/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0032 - recall: 0.7384 - val_loss: 0.0030 - val_recall: 0.8243\n",
            "Epoch 26/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0034 - recall: 0.7297 - val_loss: 0.0038 - val_recall: 0.8378\n",
            "Epoch 27/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0033 - recall: 0.7238 - val_loss: 0.0030 - val_recall: 0.8243\n",
            "Epoch 28/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0034 - recall: 0.7297 - val_loss: 0.0035 - val_recall: 0.8311\n",
            "Epoch 29/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0041 - recall: 0.7355 - val_loss: 0.0035 - val_recall: 0.8311\n",
            "Epoch 30/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0035 - recall: 0.7384 - val_loss: 0.0030 - val_recall: 0.8311\n",
            "Epoch 31/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0037 - recall: 0.7384 - val_loss: 0.0030 - val_recall: 0.8311\n",
            "Epoch 32/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0031 - recall: 0.7471 - val_loss: 0.0031 - val_recall: 0.8243\n",
            "Epoch 33/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0030 - recall: 0.7500 - val_loss: 0.0030 - val_recall: 0.8243\n",
            "Epoch 34/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0031 - recall: 0.7355 - val_loss: 0.0032 - val_recall: 0.8176\n",
            "Epoch 35/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0031 - recall: 0.7529 - val_loss: 0.0027 - val_recall: 0.8108\n",
            "Epoch 36/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0068 - recall: 0.7093 - val_loss: 0.0084 - val_recall: 0.7432\n",
            "Epoch 37/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0054 - recall: 0.7326 - val_loss: 0.0030 - val_recall: 0.8041\n",
            "Epoch 38/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0030 - recall: 0.7529 - val_loss: 0.0028 - val_recall: 0.7770\n",
            "Epoch 39/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0030 - recall: 0.7413 - val_loss: 0.0028 - val_recall: 0.8108\n",
            "Epoch 40/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0032 - recall: 0.7529 - val_loss: 0.0031 - val_recall: 0.8176\n",
            "Epoch 41/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0041 - recall: 0.7355 - val_loss: 0.0035 - val_recall: 0.8311\n",
            "Epoch 42/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0031 - recall: 0.7558 - val_loss: 0.0031 - val_recall: 0.8311\n",
            "Epoch 43/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0030 - recall: 0.7500 - val_loss: 0.0030 - val_recall: 0.8378\n",
            "Epoch 44/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0030 - recall: 0.7413 - val_loss: 0.0030 - val_recall: 0.8243\n",
            "Epoch 45/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0031 - recall: 0.7500 - val_loss: 0.0028 - val_recall: 0.8108\n",
            "Epoch 46/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0042 - recall: 0.7180 - val_loss: 0.0032 - val_recall: 0.7838\n",
            "Epoch 47/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0030 - recall: 0.7471 - val_loss: 0.0028 - val_recall: 0.8176\n",
            "Epoch 48/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0030 - recall: 0.7529 - val_loss: 0.0033 - val_recall: 0.8311\n",
            "Epoch 49/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0039 - recall: 0.7297 - val_loss: 0.0033 - val_recall: 0.8311\n",
            "Epoch 50/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0034 - recall: 0.7500 - val_loss: 0.0028 - val_recall: 0.7973\n",
            "Epoch 51/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0027 - recall: 0.7529 - val_loss: 0.0028 - val_recall: 0.7905\n",
            "Epoch 52/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0029 - recall: 0.7616 - val_loss: 0.0039 - val_recall: 0.8243\n",
            "Epoch 53/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0051 - recall: 0.7355 - val_loss: 0.0033 - val_recall: 0.7568\n",
            "Epoch 54/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0033 - recall: 0.7558 - val_loss: 0.0028 - val_recall: 0.8041\n",
            "Epoch 55/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0047 - recall: 0.7151 - val_loss: 0.0033 - val_recall: 0.8311\n",
            "Epoch 56/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0030 - recall: 0.7529 - val_loss: 0.0034 - val_recall: 0.8243\n",
            "Epoch 57/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0030 - recall: 0.7529 - val_loss: 0.0027 - val_recall: 0.8108\n",
            "Epoch 58/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0046 - recall: 0.7180 - val_loss: 0.0035 - val_recall: 0.8311\n",
            "Epoch 59/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0044 - recall: 0.7326 - val_loss: 0.0027 - val_recall: 0.8108\n",
            "Epoch 60/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0027 - recall: 0.7587 - val_loss: 0.0030 - val_recall: 0.8176\n",
            "Epoch 61/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0028 - recall: 0.7529 - val_loss: 0.0027 - val_recall: 0.8108\n",
            "Epoch 62/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0027 - recall: 0.7587 - val_loss: 0.0028 - val_recall: 0.8243\n",
            "Epoch 63/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0062 - recall: 0.7064 - val_loss: 0.0036 - val_recall: 0.8378\n",
            "Epoch 64/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0029 - recall: 0.7558 - val_loss: 0.0029 - val_recall: 0.8176\n",
            "Epoch 65/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0040 - recall: 0.7006 - val_loss: 0.0026 - val_recall: 0.8176\n",
            "Epoch 66/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0031 - recall: 0.7587 - val_loss: 0.0027 - val_recall: 0.8041\n",
            "Epoch 67/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0028 - recall: 0.7587 - val_loss: 0.0033 - val_recall: 0.8243\n",
            "Epoch 68/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0027 - recall: 0.7529 - val_loss: 0.0027 - val_recall: 0.8311\n",
            "Epoch 69/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0026 - recall: 0.7616 - val_loss: 0.0028 - val_recall: 0.8108\n",
            "Epoch 70/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0030 - recall: 0.7529 - val_loss: 0.0027 - val_recall: 0.8108\n",
            "Epoch 71/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0032 - recall: 0.7442 - val_loss: 0.0032 - val_recall: 0.8176\n",
            "Epoch 72/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0029 - recall: 0.7587 - val_loss: 0.0029 - val_recall: 0.8108\n",
            "Epoch 73/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0028 - recall: 0.7616 - val_loss: 0.0028 - val_recall: 0.8108\n",
            "Epoch 74/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0028 - recall: 0.7616 - val_loss: 0.0027 - val_recall: 0.7973\n",
            "Epoch 75/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0030 - recall: 0.7500 - val_loss: 0.0027 - val_recall: 0.7297\n",
            "Epoch 76/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0027 - recall: 0.7529 - val_loss: 0.0026 - val_recall: 0.8041\n",
            "Epoch 77/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0028 - recall: 0.7529 - val_loss: 0.0029 - val_recall: 0.8311\n",
            "Epoch 78/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0030 - recall: 0.7529 - val_loss: 0.0028 - val_recall: 0.8176\n",
            "Epoch 79/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0028 - recall: 0.7558 - val_loss: 0.0026 - val_recall: 0.8108\n",
            "Epoch 80/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0050 - recall: 0.7267 - val_loss: 0.0029 - val_recall: 0.8176\n",
            "Epoch 81/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0030 - recall: 0.7587 - val_loss: 0.0027 - val_recall: 0.7905\n",
            "Epoch 82/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0027 - recall: 0.7645 - val_loss: 0.0028 - val_recall: 0.8176\n",
            "Epoch 83/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0028 - recall: 0.7587 - val_loss: 0.0032 - val_recall: 0.8311\n",
            "Epoch 84/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0027 - recall: 0.7645 - val_loss: 0.0029 - val_recall: 0.7635\n",
            "Epoch 85/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0028 - recall: 0.7500 - val_loss: 0.0026 - val_recall: 0.8243\n",
            "Epoch 86/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0026 - recall: 0.7587 - val_loss: 0.0027 - val_recall: 0.7770\n",
            "Epoch 87/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0028 - recall: 0.7500 - val_loss: 0.0031 - val_recall: 0.8108\n",
            "Epoch 88/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0030 - recall: 0.7558 - val_loss: 0.0028 - val_recall: 0.8176\n",
            "Epoch 89/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0035 - recall: 0.7326 - val_loss: 0.0052 - val_recall: 0.7703\n",
            "Epoch 90/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0040 - recall: 0.7500 - val_loss: 0.0026 - val_recall: 0.8176\n",
            "Epoch 91/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0038 - recall: 0.7471 - val_loss: 0.0027 - val_recall: 0.8176\n",
            "Epoch 92/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0026 - recall: 0.7645 - val_loss: 0.0025 - val_recall: 0.8243\n",
            "Epoch 93/300\n",
            "195/195 [==============================] - 1s 4ms/step - loss: 0.0025 - recall: 0.7558 - val_loss: 0.0027 - val_recall: 0.8243\n",
            "Epoch 94/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0028 - recall: 0.7529 - val_loss: 0.0031 - val_recall: 0.8378\n",
            "Epoch 95/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0027 - recall: 0.7616 - val_loss: 0.0027 - val_recall: 0.8378\n",
            "Epoch 96/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0027 - recall: 0.7558 - val_loss: 0.0028 - val_recall: 0.8378\n",
            "Epoch 97/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0025 - recall: 0.7674 - val_loss: 0.0026 - val_recall: 0.7973\n",
            "Epoch 98/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0026 - recall: 0.7616 - val_loss: 0.0027 - val_recall: 0.8243\n",
            "Epoch 99/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0027 - recall: 0.7587 - val_loss: 0.0027 - val_recall: 0.8378\n",
            "Epoch 100/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0030 - recall: 0.7529 - val_loss: 0.0028 - val_recall: 0.8243\n",
            "Epoch 101/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0042 - recall: 0.7500 - val_loss: 0.0029 - val_recall: 0.8108\n",
            "Epoch 102/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0027 - recall: 0.7616 - val_loss: 0.0025 - val_recall: 0.8041\n",
            "Epoch 103/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0032 - recall: 0.7384 - val_loss: 0.0026 - val_recall: 0.8311\n",
            "Epoch 104/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0029 - recall: 0.7500 - val_loss: 0.0026 - val_recall: 0.8176\n",
            "Epoch 105/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0027 - recall: 0.7616 - val_loss: 0.0027 - val_recall: 0.8108\n",
            "Epoch 106/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0026 - recall: 0.7616 - val_loss: 0.0026 - val_recall: 0.8176\n",
            "Epoch 107/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0026 - recall: 0.7674 - val_loss: 0.0026 - val_recall: 0.8243\n",
            "Epoch 108/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0027 - recall: 0.7616 - val_loss: 0.0029 - val_recall: 0.8378\n",
            "Epoch 109/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0048 - recall: 0.7355 - val_loss: 0.0027 - val_recall: 0.8176\n",
            "Epoch 110/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0039 - recall: 0.7180 - val_loss: 0.0042 - val_recall: 0.7905\n",
            "Epoch 111/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0031 - recall: 0.7587 - val_loss: 0.0027 - val_recall: 0.8243\n",
            "Epoch 112/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0065 - recall: 0.7209 - val_loss: 0.0055 - val_recall: 0.7770\n",
            "Epoch 113/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0046 - recall: 0.7355 - val_loss: 0.0030 - val_recall: 0.8311\n",
            "Epoch 114/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0025 - recall: 0.7587 - val_loss: 0.0025 - val_recall: 0.8108\n",
            "Epoch 115/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0026 - recall: 0.7558 - val_loss: 0.0027 - val_recall: 0.8243\n",
            "Epoch 116/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0024 - recall: 0.7616 - val_loss: 0.0026 - val_recall: 0.8108\n",
            "Epoch 117/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0037 - recall: 0.7355 - val_loss: 0.0027 - val_recall: 0.8311\n",
            "Epoch 118/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0026 - recall: 0.7703 - val_loss: 0.0027 - val_recall: 0.8176\n",
            "Epoch 119/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0024 - recall: 0.7733 - val_loss: 0.0029 - val_recall: 0.7432\n",
            "Epoch 120/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0025 - recall: 0.7558 - val_loss: 0.0025 - val_recall: 0.8176\n",
            "Epoch 121/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0024 - recall: 0.7587 - val_loss: 0.0028 - val_recall: 0.8108\n",
            "Epoch 122/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0025 - recall: 0.7703 - val_loss: 0.0026 - val_recall: 0.8108\n",
            "Epoch 123/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0026 - recall: 0.7587 - val_loss: 0.0027 - val_recall: 0.8243\n",
            "Epoch 124/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0026 - recall: 0.7645 - val_loss: 0.0031 - val_recall: 0.8311\n",
            "Epoch 125/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0026 - recall: 0.7674 - val_loss: 0.0027 - val_recall: 0.8243\n",
            "Epoch 126/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0027 - recall: 0.7674 - val_loss: 0.0026 - val_recall: 0.7973\n",
            "Epoch 127/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0025 - recall: 0.7587 - val_loss: 0.0028 - val_recall: 0.8378\n",
            "Epoch 128/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0026 - recall: 0.7616 - val_loss: 0.0025 - val_recall: 0.8176\n",
            "Epoch 129/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0034 - recall: 0.7500 - val_loss: 0.0031 - val_recall: 0.7635\n",
            "Epoch 130/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0026 - recall: 0.7500 - val_loss: 0.0038 - val_recall: 0.7703\n",
            "Epoch 131/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0032 - recall: 0.7529 - val_loss: 0.0027 - val_recall: 0.8311\n",
            "Epoch 132/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0026 - recall: 0.7587 - val_loss: 0.0027 - val_recall: 0.8243\n",
            "Epoch 133/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0025 - recall: 0.7645 - val_loss: 0.0028 - val_recall: 0.8378\n",
            "Epoch 134/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0027 - recall: 0.7616 - val_loss: 0.0025 - val_recall: 0.8041\n",
            "Epoch 135/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0026 - recall: 0.7587 - val_loss: 0.0026 - val_recall: 0.8243\n",
            "Epoch 136/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0027 - recall: 0.7616 - val_loss: 0.0029 - val_recall: 0.8041\n",
            "Epoch 137/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0025 - recall: 0.7645 - val_loss: 0.0027 - val_recall: 0.8243\n",
            "Epoch 138/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0026 - recall: 0.7645 - val_loss: 0.0034 - val_recall: 0.8108\n",
            "Epoch 139/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0028 - recall: 0.7442 - val_loss: 0.0027 - val_recall: 0.8243\n",
            "Epoch 140/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0026 - recall: 0.7616 - val_loss: 0.0030 - val_recall: 0.8243\n",
            "Epoch 141/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0025 - recall: 0.7674 - val_loss: 0.0025 - val_recall: 0.7568\n",
            "Epoch 142/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0026 - recall: 0.7587 - val_loss: 0.0026 - val_recall: 0.7973\n",
            "Epoch 143/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0032 - recall: 0.7471 - val_loss: 0.0025 - val_recall: 0.8243\n",
            "Epoch 144/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0025 - recall: 0.7558 - val_loss: 0.0032 - val_recall: 0.8378\n",
            "Epoch 145/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0043 - recall: 0.7326 - val_loss: 0.0028 - val_recall: 0.8243\n",
            "Epoch 146/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0024 - recall: 0.7558 - val_loss: 0.0028 - val_recall: 0.8243\n",
            "Epoch 147/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0025 - recall: 0.7616 - val_loss: 0.0028 - val_recall: 0.7973\n",
            "Epoch 148/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0028 - recall: 0.7558 - val_loss: 0.0025 - val_recall: 0.8243\n",
            "Epoch 149/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0023 - recall: 0.7645 - val_loss: 0.0046 - val_recall: 0.8311\n",
            "Epoch 150/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0028 - recall: 0.7442 - val_loss: 0.0030 - val_recall: 0.8311\n",
            "Epoch 151/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0025 - recall: 0.7587 - val_loss: 0.0035 - val_recall: 0.8378\n",
            "Epoch 152/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0023 - recall: 0.7616 - val_loss: 0.0027 - val_recall: 0.7973\n",
            "Epoch 153/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0025 - recall: 0.7645 - val_loss: 0.0026 - val_recall: 0.8176\n",
            "Epoch 154/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0024 - recall: 0.7587 - val_loss: 0.0026 - val_recall: 0.8041\n",
            "Epoch 155/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0023 - recall: 0.7645 - val_loss: 0.0026 - val_recall: 0.8176\n",
            "Epoch 156/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0025 - recall: 0.7500 - val_loss: 0.0026 - val_recall: 0.8243\n",
            "Epoch 157/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0044 - recall: 0.7093 - val_loss: 0.0030 - val_recall: 0.8311\n",
            "Epoch 158/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0025 - recall: 0.7558 - val_loss: 0.0026 - val_recall: 0.7770\n",
            "Epoch 159/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0025 - recall: 0.7587 - val_loss: 0.0025 - val_recall: 0.8176\n",
            "Epoch 160/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0027 - recall: 0.7529 - val_loss: 0.0027 - val_recall: 0.8176\n",
            "Epoch 161/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0024 - recall: 0.7587 - val_loss: 0.0027 - val_recall: 0.8041\n",
            "Epoch 162/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0023 - recall: 0.7558 - val_loss: 0.0026 - val_recall: 0.8108\n",
            "Epoch 163/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0029 - recall: 0.7442 - val_loss: 0.0026 - val_recall: 0.7703\n",
            "Epoch 164/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0025 - recall: 0.7471 - val_loss: 0.0030 - val_recall: 0.8108\n",
            "Epoch 165/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0025 - recall: 0.7587 - val_loss: 0.0025 - val_recall: 0.8108\n",
            "Epoch 166/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0028 - recall: 0.7529 - val_loss: 0.0034 - val_recall: 0.8108\n",
            "Epoch 167/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0026 - recall: 0.7587 - val_loss: 0.0025 - val_recall: 0.8176\n",
            "Epoch 168/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0023 - recall: 0.7645 - val_loss: 0.0025 - val_recall: 0.8176\n",
            "Epoch 169/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0029 - recall: 0.7500 - val_loss: 0.0027 - val_recall: 0.7973\n",
            "Epoch 170/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0024 - recall: 0.7616 - val_loss: 0.0025 - val_recall: 0.8176\n",
            "Epoch 171/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0023 - recall: 0.7645 - val_loss: 0.0028 - val_recall: 0.8311\n",
            "Epoch 172/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0051 - recall: 0.6948 - val_loss: 0.0068 - val_recall: 0.7770\n",
            "Epoch 173/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0051 - recall: 0.7500 - val_loss: 0.0027 - val_recall: 0.8378\n",
            "Epoch 174/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0023 - recall: 0.7791 - val_loss: 0.0042 - val_recall: 0.8311\n",
            "Epoch 175/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0024 - recall: 0.7849 - val_loss: 0.0032 - val_recall: 0.8243\n",
            "Epoch 176/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0023 - recall: 0.7878 - val_loss: 0.0029 - val_recall: 0.8446\n",
            "Epoch 177/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0022 - recall: 0.7820 - val_loss: 0.0029 - val_recall: 0.8378\n",
            "Epoch 178/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0023 - recall: 0.7849 - val_loss: 0.0026 - val_recall: 0.8311\n",
            "Epoch 179/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0023 - recall: 0.7703 - val_loss: 0.0026 - val_recall: 0.8446\n",
            "Epoch 180/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0022 - recall: 0.7849 - val_loss: 0.0025 - val_recall: 0.7838\n",
            "Epoch 181/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0030 - recall: 0.7616 - val_loss: 0.0026 - val_recall: 0.7703\n",
            "Epoch 182/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0031 - recall: 0.7616 - val_loss: 0.0029 - val_recall: 0.8446\n",
            "Epoch 183/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0023 - recall: 0.7878 - val_loss: 0.0025 - val_recall: 0.8514\n",
            "Epoch 184/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0023 - recall: 0.7820 - val_loss: 0.0042 - val_recall: 0.8243\n",
            "Epoch 185/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0028 - recall: 0.7733 - val_loss: 0.0026 - val_recall: 0.8378\n",
            "Epoch 186/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0023 - recall: 0.7878 - val_loss: 0.0026 - val_recall: 0.8041\n",
            "Epoch 187/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0031 - recall: 0.7558 - val_loss: 0.0026 - val_recall: 0.8176\n",
            "Epoch 188/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0022 - recall: 0.7878 - val_loss: 0.0027 - val_recall: 0.8446\n",
            "Epoch 189/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0024 - recall: 0.7878 - val_loss: 0.0026 - val_recall: 0.8311\n",
            "Epoch 190/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0034 - recall: 0.7616 - val_loss: 0.0025 - val_recall: 0.8378\n",
            "Epoch 191/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0026 - recall: 0.7791 - val_loss: 0.0028 - val_recall: 0.8649\n",
            "Epoch 192/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0022 - recall: 0.7936 - val_loss: 0.0025 - val_recall: 0.7973\n",
            "Epoch 193/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0021 - recall: 0.7936 - val_loss: 0.0025 - val_recall: 0.7973\n",
            "Epoch 194/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0023 - recall: 0.7878 - val_loss: 0.0029 - val_recall: 0.7973\n",
            "Epoch 195/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0024 - recall: 0.7762 - val_loss: 0.0026 - val_recall: 0.8108\n",
            "Epoch 196/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0023 - recall: 0.7820 - val_loss: 0.0027 - val_recall: 0.8378\n",
            "Epoch 197/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0040 - recall: 0.7529 - val_loss: 0.0028 - val_recall: 0.7973\n",
            "Epoch 198/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0023 - recall: 0.7878 - val_loss: 0.0026 - val_recall: 0.8378\n",
            "Epoch 199/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0021 - recall: 0.7936 - val_loss: 0.0026 - val_recall: 0.8108\n",
            "Epoch 200/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0024 - recall: 0.7849 - val_loss: 0.0026 - val_recall: 0.7635\n",
            "Epoch 201/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0021 - recall: 0.7849 - val_loss: 0.0024 - val_recall: 0.8176\n",
            "Epoch 202/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0022 - recall: 0.7820 - val_loss: 0.0026 - val_recall: 0.8041\n",
            "Epoch 203/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0022 - recall: 0.7965 - val_loss: 0.0028 - val_recall: 0.8243\n",
            "Epoch 204/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0021 - recall: 0.7849 - val_loss: 0.0026 - val_recall: 0.8176\n",
            "Epoch 205/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0021 - recall: 0.7878 - val_loss: 0.0026 - val_recall: 0.8311\n",
            "Epoch 206/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0022 - recall: 0.7849 - val_loss: 0.0027 - val_recall: 0.8243\n",
            "Epoch 207/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0023 - recall: 0.7791 - val_loss: 0.0025 - val_recall: 0.8446\n",
            "Epoch 208/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0024 - recall: 0.7907 - val_loss: 0.0026 - val_recall: 0.8243\n",
            "Epoch 209/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0040 - recall: 0.7529 - val_loss: 0.0031 - val_recall: 0.8108\n",
            "Epoch 210/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0024 - recall: 0.7965 - val_loss: 0.0029 - val_recall: 0.8311\n",
            "Epoch 211/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0023 - recall: 0.7878 - val_loss: 0.0029 - val_recall: 0.8311\n",
            "Epoch 212/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0022 - recall: 0.7878 - val_loss: 0.0025 - val_recall: 0.8041\n",
            "Epoch 213/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0021 - recall: 0.7965 - val_loss: 0.0025 - val_recall: 0.8311\n",
            "Epoch 214/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0025 - recall: 0.7907 - val_loss: 0.0027 - val_recall: 0.8176\n",
            "Epoch 215/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0022 - recall: 0.7965 - val_loss: 0.0026 - val_recall: 0.8176\n",
            "Epoch 216/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0024 - recall: 0.7878 - val_loss: 0.0028 - val_recall: 0.8243\n",
            "Epoch 217/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0023 - recall: 0.7907 - val_loss: 0.0028 - val_recall: 0.8446\n",
            "Epoch 218/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0023 - recall: 0.7907 - val_loss: 0.0026 - val_recall: 0.8378\n",
            "Epoch 219/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0022 - recall: 0.8023 - val_loss: 0.0025 - val_recall: 0.8243\n",
            "Epoch 220/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0021 - recall: 0.7994 - val_loss: 0.0026 - val_recall: 0.8311\n",
            "Epoch 221/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0023 - recall: 0.7907 - val_loss: 0.0026 - val_recall: 0.8311\n",
            "Epoch 222/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0022 - recall: 0.7791 - val_loss: 0.0027 - val_recall: 0.8311\n",
            "Epoch 223/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0021 - recall: 0.7965 - val_loss: 0.0027 - val_recall: 0.8378\n",
            "Epoch 224/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0022 - recall: 0.7820 - val_loss: 0.0028 - val_recall: 0.8378\n",
            "Epoch 225/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0021 - recall: 0.7936 - val_loss: 0.0032 - val_recall: 0.8176\n",
            "Epoch 226/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0025 - recall: 0.7936 - val_loss: 0.0027 - val_recall: 0.8176\n",
            "Epoch 227/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0022 - recall: 0.7907 - val_loss: 0.0030 - val_recall: 0.8446\n",
            "Epoch 228/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0026 - recall: 0.7733 - val_loss: 0.0031 - val_recall: 0.8514\n",
            "Epoch 229/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0023 - recall: 0.7965 - val_loss: 0.0028 - val_recall: 0.8446\n",
            "Epoch 230/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0024 - recall: 0.7907 - val_loss: 0.0026 - val_recall: 0.8378\n",
            "Epoch 231/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0021 - recall: 0.7936 - val_loss: 0.0027 - val_recall: 0.8446\n",
            "Epoch 232/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0021 - recall: 0.7907 - val_loss: 0.0027 - val_recall: 0.8243\n",
            "Epoch 233/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0021 - recall: 0.7936 - val_loss: 0.0027 - val_recall: 0.8378\n",
            "Epoch 234/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0021 - recall: 0.7849 - val_loss: 0.0028 - val_recall: 0.8446\n",
            "Epoch 235/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0024 - recall: 0.7849 - val_loss: 0.0027 - val_recall: 0.8311\n",
            "Epoch 236/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0022 - recall: 0.7936 - val_loss: 0.0026 - val_recall: 0.8446\n",
            "Epoch 237/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0022 - recall: 0.7849 - val_loss: 0.0033 - val_recall: 0.8446\n",
            "Epoch 238/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0023 - recall: 0.7849 - val_loss: 0.0026 - val_recall: 0.8446\n",
            "Epoch 239/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0022 - recall: 0.7907 - val_loss: 0.0029 - val_recall: 0.8311\n",
            "Epoch 240/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0022 - recall: 0.7994 - val_loss: 0.0027 - val_recall: 0.8378\n",
            "Epoch 241/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0022 - recall: 0.7936 - val_loss: 0.0029 - val_recall: 0.8446\n",
            "Epoch 242/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0023 - recall: 0.7965 - val_loss: 0.0036 - val_recall: 0.8176\n",
            "Epoch 243/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0022 - recall: 0.7936 - val_loss: 0.0028 - val_recall: 0.8311\n",
            "Epoch 244/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0022 - recall: 0.7936 - val_loss: 0.0027 - val_recall: 0.8378\n",
            "Epoch 245/300\n",
            "195/195 [==============================] - 1s 4ms/step - loss: 0.0028 - recall: 0.7791 - val_loss: 0.0030 - val_recall: 0.8514\n",
            "Epoch 246/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0022 - recall: 0.7994 - val_loss: 0.0028 - val_recall: 0.8378\n",
            "Epoch 247/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0020 - recall: 0.7994 - val_loss: 0.0028 - val_recall: 0.8311\n",
            "Epoch 248/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0022 - recall: 0.7878 - val_loss: 0.0027 - val_recall: 0.8581\n",
            "Epoch 249/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0020 - recall: 0.7965 - val_loss: 0.0026 - val_recall: 0.8378\n",
            "Epoch 250/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0021 - recall: 0.7936 - val_loss: 0.0027 - val_recall: 0.7770\n",
            "Epoch 251/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0022 - recall: 0.7994 - val_loss: 0.0028 - val_recall: 0.8311\n",
            "Epoch 252/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0021 - recall: 0.7907 - val_loss: 0.0030 - val_recall: 0.8378\n",
            "Epoch 253/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0021 - recall: 0.7907 - val_loss: 0.0028 - val_recall: 0.8041\n",
            "Epoch 254/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0030 - recall: 0.7820 - val_loss: 0.0034 - val_recall: 0.8378\n",
            "Epoch 255/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0021 - recall: 0.7965 - val_loss: 0.0028 - val_recall: 0.8378\n",
            "Epoch 256/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0021 - recall: 0.7907 - val_loss: 0.0028 - val_recall: 0.8446\n",
            "Epoch 257/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0021 - recall: 0.8023 - val_loss: 0.0030 - val_recall: 0.8243\n",
            "Epoch 258/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0021 - recall: 0.8023 - val_loss: 0.0030 - val_recall: 0.8378\n",
            "Epoch 259/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0021 - recall: 0.7849 - val_loss: 0.0031 - val_recall: 0.8378\n",
            "Epoch 260/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0027 - recall: 0.7820 - val_loss: 0.0028 - val_recall: 0.8446\n",
            "Epoch 261/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0021 - recall: 0.8081 - val_loss: 0.0028 - val_recall: 0.8311\n",
            "Epoch 262/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0021 - recall: 0.8052 - val_loss: 0.0031 - val_recall: 0.7973\n",
            "Epoch 263/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0020 - recall: 0.7965 - val_loss: 0.0034 - val_recall: 0.7027\n",
            "Epoch 264/300\n",
            "195/195 [==============================] - 1s 4ms/step - loss: 0.0026 - recall: 0.7820 - val_loss: 0.0031 - val_recall: 0.8378\n",
            "Epoch 265/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0020 - recall: 0.8023 - val_loss: 0.0030 - val_recall: 0.8041\n",
            "Epoch 266/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0022 - recall: 0.7965 - val_loss: 0.0028 - val_recall: 0.8041\n",
            "Epoch 267/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0020 - recall: 0.7878 - val_loss: 0.0029 - val_recall: 0.8311\n",
            "Epoch 268/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0021 - recall: 0.7965 - val_loss: 0.0031 - val_recall: 0.8243\n",
            "Epoch 269/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0023 - recall: 0.7994 - val_loss: 0.0030 - val_recall: 0.7838\n",
            "Epoch 270/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0022 - recall: 0.8023 - val_loss: 0.0030 - val_recall: 0.7973\n",
            "Epoch 271/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0020 - recall: 0.8052 - val_loss: 0.0028 - val_recall: 0.8311\n",
            "Epoch 272/300\n",
            "195/195 [==============================] - 1s 4ms/step - loss: 0.0021 - recall: 0.8052 - val_loss: 0.0032 - val_recall: 0.8243\n",
            "Epoch 273/300\n",
            "195/195 [==============================] - 1s 4ms/step - loss: 0.0022 - recall: 0.7936 - val_loss: 0.0029 - val_recall: 0.8311\n",
            "Epoch 274/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0020 - recall: 0.8110 - val_loss: 0.0039 - val_recall: 0.8446\n",
            "Epoch 275/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0020 - recall: 0.7994 - val_loss: 0.0030 - val_recall: 0.8243\n",
            "Epoch 276/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0021 - recall: 0.7936 - val_loss: 0.0030 - val_recall: 0.8311\n",
            "Epoch 277/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0033 - recall: 0.7907 - val_loss: 0.0033 - val_recall: 0.8514\n",
            "Epoch 278/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0022 - recall: 0.7994 - val_loss: 0.0030 - val_recall: 0.8243\n",
            "Epoch 279/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0020 - recall: 0.8081 - val_loss: 0.0029 - val_recall: 0.7905\n",
            "Epoch 280/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0021 - recall: 0.7849 - val_loss: 0.0029 - val_recall: 0.8311\n",
            "Epoch 281/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0020 - recall: 0.7965 - val_loss: 0.0029 - val_recall: 0.8378\n",
            "Epoch 282/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0020 - recall: 0.7936 - val_loss: 0.0031 - val_recall: 0.8378\n",
            "Epoch 283/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0021 - recall: 0.8052 - val_loss: 0.0029 - val_recall: 0.8243\n",
            "Epoch 284/300\n",
            "195/195 [==============================] - 1s 4ms/step - loss: 0.0027 - recall: 0.7791 - val_loss: 0.0032 - val_recall: 0.8446\n",
            "Epoch 285/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0021 - recall: 0.8052 - val_loss: 0.0031 - val_recall: 0.8041\n",
            "Epoch 286/300\n",
            "195/195 [==============================] - 1s 4ms/step - loss: 0.0021 - recall: 0.8052 - val_loss: 0.0032 - val_recall: 0.8378\n",
            "Epoch 287/300\n",
            "195/195 [==============================] - 1s 4ms/step - loss: 0.0020 - recall: 0.7936 - val_loss: 0.0033 - val_recall: 0.8446\n",
            "Epoch 288/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0021 - recall: 0.8052 - val_loss: 0.0043 - val_recall: 0.8446\n",
            "Epoch 289/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0020 - recall: 0.7936 - val_loss: 0.0029 - val_recall: 0.8041\n",
            "Epoch 290/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0020 - recall: 0.8081 - val_loss: 0.0032 - val_recall: 0.8108\n",
            "Epoch 291/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0019 - recall: 0.8198 - val_loss: 0.0030 - val_recall: 0.7770\n",
            "Epoch 292/300\n",
            "195/195 [==============================] - 1s 4ms/step - loss: 0.0020 - recall: 0.7878 - val_loss: 0.0032 - val_recall: 0.8378\n",
            "Epoch 293/300\n",
            "195/195 [==============================] - 1s 4ms/step - loss: 0.0024 - recall: 0.7878 - val_loss: 0.0032 - val_recall: 0.8041\n",
            "Epoch 294/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0020 - recall: 0.8110 - val_loss: 0.0030 - val_recall: 0.8378\n",
            "Epoch 295/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0021 - recall: 0.8169 - val_loss: 0.0030 - val_recall: 0.8243\n",
            "Epoch 296/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0021 - recall: 0.7965 - val_loss: 0.0036 - val_recall: 0.7703\n",
            "Epoch 297/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0029 - recall: 0.7907 - val_loss: 0.0031 - val_recall: 0.8311\n",
            "Epoch 298/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0020 - recall: 0.8081 - val_loss: 0.0029 - val_recall: 0.8108\n",
            "Epoch 299/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0019 - recall: 0.8140 - val_loss: 0.0031 - val_recall: 0.8378\n",
            "Epoch 300/300\n",
            "195/195 [==============================] - 1s 3ms/step - loss: 0.0026 - recall: 0.7878 - val_loss: 0.0033 - val_recall: 0.8041\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FdBHeQZLR0D"
      },
      "source": [
        "## 4) Model Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQvxJpH5FYjD",
        "outputId": "aa734680-f442-4674-8a1c-d7c6808a4d88"
      },
      "source": [
        "loss, recall = Model_fd.evaluate(X_test, y_test)\n",
        "\n",
        "print('loss = {:.2f}'.format(loss))\n",
        "print('recall = {:.2f}'.format(recall))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2671/2671 [==============================] - 3s 1ms/step - loss: 0.0033 - recall: 0.8041\n",
            "loss = 0.00\n",
            "recall = 0.80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HU164BqcLjvG"
      },
      "source": [
        "## 5) Model Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7dPNBwnFYfV",
        "outputId": "0c018e83-ae53-4854-989c-36b404035eed"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "np.set_printoptions(suppress=True, precision=5)\n",
        "\n",
        "Model_fd.predict(X_test)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.     ],\n",
              "       [0.00149],\n",
              "       [0.     ],\n",
              "       ...,\n",
              "       [0.     ],\n",
              "       [0.     ],\n",
              "       [0.     ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4i_1DoyLvJc",
        "outputId": "27a349ff-3788-42a9-9b66-8d831b44cc66"
      },
      "source": [
        "y_hat = np.argmax(Model_fd.predict(X_test), axis = 1)\n",
        "\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "confusion_matrix(y_test, y_hat)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[85295,     0],\n",
              "       [  148,     0]])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylReVf0WSRDa"
      },
      "source": [
        "# \n",
        "# \n",
        "# \n",
        "# The End\n",
        "# \n",
        "# \n",
        "# "
      ]
    }
  ]
}